import streamlit as st
import pandas as pd
# from textblob import TextBlob # TextBlob is less effective for Korean
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import re
import matplotlib.font_manager as fm
from konlpy.tag import Okt

# Initialize Konlpy Okt tagger
okt = Okt()

# Define simple Korean sentiment lexicon (can be expanded)
sentiment_lexicon = {
    'Í∏çÏ†ï': ['ÎßåÏ°±', 'Ï¢ã', 'ÏµúÍ≥†', 'Ï∂îÏ≤ú', 'Í∞êÏÇ¨', 'ÌõåÎ•≠', 'Ìé∏Î¶¨', 'Ïã†ÏÑ†', 'ÎßõÏûà', 'ÏπúÏ†à', 'Îπ†Î•¥'],
    'Î∂ÄÏ†ï': ['Î∂àÎßå', 'ÎÇòÏÅò', 'ÏïÑÏâΩ', 'Î≥ÑÎ°ú', 'Î¨∏Ï†ú', 'ÎäêÎ¶¨', 'Ïûë', 'ÌÅ¨', 'Ïñ¥Î†µ', 'ÏàòÏ∂ï', 'Î∂ÄÏ°±', 'Í∏∞ÎåÄÏù¥Ìïò', 'ÎπÑÏã∏']
}

# For Korean font in matplotlib
font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf' # Linux (adjust as needed)
# font_path = 'C:/Windows/Fonts/malgun.ttf' # Windows

try:
    # Clear font cache to ensure new font is loaded
    fm._load_fontmanager(try_read_cache=False)
    
    # Add the font file to FontManager (if not already added)
    if font_path not in [f.fname for f in fm.fontManager.ttflist]:
        fm.fontManager.addfont(font_path)
    
    # Set the font family to the known font name
    plt.rcParams['font.family'] = 'NanumGothic' # Use the exact font name
    plt.rcParams['axes.unicode_minus'] = False # minus sign
    st.success(f"'NanumGothic' Ìè∞Ìä∏Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÑ§Ï†ïÎêòÏóàÏäµÎãàÎã§.")
except FileNotFoundError:
    st.error(f"'{font_path}' Ìè∞Ìä∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Í∑∏ÎûòÌîÑÏóê ÌïúÍ∏ÄÏù¥ Íπ®Ï†∏ Î≥¥Ïùº Ïàò ÏûàÏäµÎãàÎã§. Í≤ΩÎ°úÎ•º ÌôïÏù∏ÌïòÍ±∞ÎÇò Îã§Î•∏ ÌïúÍ∏Ä Ìè∞Ìä∏Î•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî.")
    st.stop() # Stop the app if font file is not found
except Exception as e:
    st.error(f"Ìè∞Ìä∏ ÏÑ§Ï†ï Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}. Í∑∏ÎûòÌîÑÏóê ÌïúÍ∏ÄÏù¥ Íπ®Ï†∏ Î≥¥Ïùº Ïàò ÏûàÏäµÎãàÎã§.")
    st.info("ÎßåÏïΩ Linux ÌôòÍ≤ΩÏù¥ÎùºÎ©¥, /usr/share/fonts/truetype/nanum/NanumGothic.ttf Í≤ΩÎ°úÎ•º ÌôïÏù∏ÌïòÍ±∞ÎÇò, Ìï¥Îãπ Í≤ΩÎ°úÏóê NanumGothic Ìè∞Ìä∏Î•º ÏÑ§ÏπòÌï¥Ï£ºÏÑ∏Ïöî.")
    st.stop() # Stop the app if other font errors occur

# Set page configuration
st.set_page_config(layout="wide", page_title="Í≥†Í∞ù ÌîºÎìúÎ∞± Î∂ÑÏÑù Ïï±", page_icon="üí¨")

st.title("üí¨ Í≥†Í∞ù ÌîºÎìúÎ∞± Î∂ÑÏÑù (Streamlit Î≤ÑÏ†Ñ)")
st.markdown("---")

st.sidebar.header("Îç∞Ïù¥ÌÑ∞ ÏÑ†ÌÉù")
use_sample_data = st.sidebar.checkbox("ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö© (feedback-data.csv)")

df = None
if use_sample_data:
    try:
        df = pd.read_csv('feedback-data.csv')
        st.sidebar.success("ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏÑ±Í≥µ!")
        st.sidebar.write("Îç∞Ïù¥ÌÑ∞ ÎØ∏Î¶¨Î≥¥Í∏∞:")
        st.sidebar.dataframe(df.head())
    except FileNotFoundError:
        st.sidebar.error("'feedback-data.csv' ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î•º Î®ºÏ†Ä ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.")
        st.stop()
    except Exception as e:
        st.sidebar.error(f"ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ Î°úÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
        st.stop()
else:
    uploaded_file = st.sidebar.file_uploader("CSV ÎòêÎäî Excel ÌååÏùº ÏóÖÎ°úÎìú", type=["csv", "xlsx"])
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.sidebar.success("ÌååÏùº ÏóÖÎ°úÎìú ÏÑ±Í≥µ!")
            st.sidebar.write("Îç∞Ïù¥ÌÑ∞ ÎØ∏Î¶¨Î≥¥Í∏∞:")
            st.sidebar.dataframe(df.head())
        except Exception as e:
            st.sidebar.error(f"ÌååÏùº Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")
            st.sidebar.warning("ÌååÏùº ÌòïÏãùÏù¥ÎÇò ÎÇ¥Ïö©Ïù¥ Ïò¨Î∞îÎ•∏ÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.")


if df is not None:
    # Select text column
    text_column = st.sidebar.selectbox("ÌîºÎìúÎ∞± ÌÖçÏä§Ìä∏ Ïª¨Îüº ÏÑ†ÌÉù", df.columns)
    if text_column:
        st.subheader("Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÏãúÏûë")
        st.write(f"ÏÑ†ÌÉùÎêú ÌÖçÏä§Ìä∏ Ïª¨Îüº: **{text_column}**")

        # --- Í∞êÏÑ± Î∂ÑÏÑù ---
        st.subheader("1. Í∞êÏÑ± Î∂ÑÏÑù")

        @st.cache_data
        def analyze_sentiment_korean(text):
            if pd.isna(text) or not isinstance(text, str):
                return "Ï§ëÎ¶Ω", 0.0
            
            score = 0
            words = okt.morphs(text, stem=True) # ÌòïÌÉúÏÜå Î∂ÑÏÑù Î∞è Ïñ¥Í∞Ñ Ï∂îÏ∂ú
            
            for word in words:
                if any(pos_word in word for pos_word in sentiment_lexicon['Í∏çÏ†ï']):
                    score += 1
                if any(neg_word in word for neg_word in sentiment_lexicon['Î∂ÄÏ†ï']):
                    score -= 1

            if score > 0:
                return "Í∏çÏ†ï", score
            elif score < 0:
                return "Î∂ÄÏ†ï", score
            else:
                return "Ï§ëÎ¶Ω", score

        # Use Korean sentiment analysis function
        df[['Í∞êÏÑ±', 'Í∞êÏÑ±_Ï†êÏàò']] = df[text_column].apply(lambda x: pd.Series(analyze_sentiment_korean(x)))

        sentiment_counts = df['Í∞êÏÑ±'].value_counts()
        fig1, ax1 = plt.subplots(figsize=(8, 6))
        sentiment_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=ax1,
                              colors=['#66b3ff', '#ff9999', '#99ff99'])
        ax1.set_ylabel('')
        ax1.set_title('Ï†ÑÏ≤¥ ÌîºÎìúÎ∞± Í∞êÏÑ± Î∂ÑÌè¨')
        st.pyplot(fig1)

        st.dataframe(df[['Í∞êÏÑ±', 'Í∞êÏÑ±_Ï†êÏàò', text_column]].head())

        # --- ÌÇ§ÏõåÎìú Ï∂îÏ∂ú ---
        st.subheader("2. Ï£ºÏöî ÌÇ§ÏõåÎìú Ï∂îÏ∂ú")

        @st.cache_data
        def extract_keywords_korean(text_series):
            all_nouns = []
            for text in text_series.dropna():
                # Î™ÖÏÇ¨Îßå Ï∂îÏ∂ú
                nouns = okt.nouns(text)
                all_nouns.extend(nouns)
            return Counter(all_nouns)

        word_counts = extract_keywords_korean(df[text_column])

        st.write("Í∞ÄÏû• ÎßéÏù¥ Ïñ∏Í∏âÎêú ÌÇ§ÏõåÎìú (ÏÉÅÏúÑ 20Í∞ú):")
        most_common_words = pd.DataFrame(word_counts.most_common(20), columns=['ÌÇ§ÏõåÎìú', 'ÎπàÎèÑ'])
        fig2, ax2 = plt.subplots(figsize=(12, 7))
        sns.barplot(x='ÎπàÎèÑ', y='ÌÇ§ÏõåÎìú', data=most_common_words, ax=ax2, palette='viridis')
        ax2.set_title('Ï£ºÏöî ÌÇ§ÏõåÎìú ÎπàÎèÑ')
        ax2.set_xlabel('ÎπàÎèÑ')
        ax2.set_ylabel('ÌÇ§ÏõåÎìú')
        st.pyplot(fig2)

        # --- ÏÉÅÏÑ∏ ÌïÑÌÑ∞ÎßÅ Î∞è Î∂ÑÏÑù ---
        st.subheader("3. ÏÉÅÏÑ∏ Î∂ÑÏÑù (ÌïÑÌÑ∞ÎßÅ)")
        st.markdown("---")

        st.write("Í∞êÏÑ±Î≥Ñ Ï£ºÏöî ÌÇ§ÏõåÎìúÎ•º ÌôïÏù∏ÌïòÍ±∞ÎÇò, ÌäπÏ†ï ÌÇ§ÏõåÎìúÎ•º Ìè¨Ìï®ÌïòÎäî ÌîºÎìúÎ∞±ÏùÑ ÌïÑÌÑ∞ÎßÅÌï† Ïàò ÏûàÏäµÎãàÎã§.")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Í∞êÏÑ±Î≥Ñ ÌÇ§ÏõåÎìú")
            selected_sentiment = st.radio("ÌôïÏù∏Ìï† Í∞êÏÑ± ÏÑ†ÌÉù", ['Í∏çÏ†ï', 'Î∂ÄÏ†ï', 'Ï§ëÎ¶Ω'])
            filtered_sentiment_df = df[df['Í∞êÏÑ±'] == selected_sentiment]
            sentiment_word_counts = extract_keywords_korean(filtered_sentiment_df[text_column])
            if sentiment_word_counts:
                most_common_sentiment_words = pd.DataFrame(sentiment_word_counts.most_common(10), columns=['ÌÇ§ÏõåÎìú', 'ÎπàÎèÑ'])
                st.dataframe(most_common_sentiment_words)
            else:
                st.write(f"'{selected_sentiment}' Í∞êÏÑ± ÌîºÎìúÎ∞±Ïù¥ ÏóÜÏäµÎãàÎã§.")

        with col2:
            st.subheader("ÌÇ§ÏõåÎìúÎ°ú ÌîºÎìúÎ∞± Í≤ÄÏÉâ")
            search_keyword = st.text_input("Í≤ÄÏÉâÌï† ÌÇ§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî (Ïòà: 'Î∞∞ÏÜ°', 'ÌíàÏßà')")
            if search_keyword:
                filtered_by_keyword_df = df[df[text_column].astype(str).str.contains(search_keyword, case=False, na=False)]
                if not filtered_by_keyword_df.empty:
                    st.write(f"'{search_keyword}'(ÏùÑ)Î•º Ìè¨Ìï®ÌïòÎäî ÌîºÎìúÎ∞±:")
                    st.dataframe(filtered_by_keyword_df[[text_column, 'Í∞êÏÑ±', 'Í∞êÏÑ±_Ï†êÏàò']])
                else:
                    st.write(f"'{search_keyword}'(ÏùÑ)Î•º Ìè¨Ìï®ÌïòÎäî ÌîºÎìúÎ∞±Ïù¥ ÏóÜÏäµÎãàÎã§.")
            else:
                st.write("ÌÇ§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏó¨ Í¥ÄÎ†® ÌîºÎìúÎ∞±ÏùÑ Ï∞æÏïÑÎ≥¥ÏÑ∏Ïöî.")

else:
    st.info("ÏôºÏ™Ω ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÍ±∞ÎÇò ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.")

st.info("ÌïúÍ∏Ä Í∞êÏÑ± Î∂ÑÏÑùÏùÄ konlpy ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÇ¨Ïö©ÌïòÎ©∞, Ï†ïÏùòÎêú Í∏çÏ†ï/Î∂ÄÏ†ï ÌÇ§ÏõåÎìúÎ•º Í∏∞Î∞òÏúºÎ°ú Î∂ÑÎ•òÎê©ÎãàÎã§. ÌÇ§ÏõåÎìú ÏÇ¨Ï†ÑÏùÄ ÌôïÏû•Ìï† Ïàò ÏûàÏäµÎãàÎã§.")
